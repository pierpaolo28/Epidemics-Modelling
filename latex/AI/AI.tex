\chapter{Artificial Intelligence}
\setcounter{secnumdepth}{5}
\label{ch:AI}
\setlength\lineskip{0pt}
\vspace*{15pt}

% \definecolor{codegreen}{rgb}{0,0.6,0}
% \definecolor{codegray}{rgb}{0.5,0.5,0.5}
% \definecolor{codepurple}{rgb}{0.58,0,0.82}
% \definecolor{backcolour}{rgb}{0.95,0.95,0.92}
% \definecolor{deepred}{rgb}{0.6,0,0}
 
% \lstdefinestyle{mystyle}{
%     backgroundcolor=\color{backcolour},   
%     commentstyle=\color{codegreen},
%     keywordstyle=\color{blue},
%     numberstyle=\tiny\color{codegray},
%     stringstyle=\color{codepurple},
%     basicstyle=\footnotesize,
%     breakatwhitespace=false,         
%     breaklines=true,                 
%     captionpos=b,                    
%     keepspaces=true,                 
%     numbers=left,                    
%     numbersep=5pt,                  
%     showspaces=false,                
%     showstringspaces=false,
%     showtabs=false,                  
%     tabsize=2
% }
 
% \lstset{style=mystyle}

As part of this chapter, the analysis of an EEG data-set to identify if a child is affected or not by autism will be outlined. Both Machine Learning (ML) and Deep Learning (DL) approaches used to tackle this task will be examined. Additionally, a Computer Vision based approach to ASD screening will be proposed.

% \section{ASD Screening Data Analysis for Toddlers}
% In this section has been made use of the "Autistic Spectrum Disorder Screening Data for Toddlers" data-set \cite{toddler}. Exploration of the data took place after Ethics Approval (Appendix E). This data-set contains 10 behavioural features (Listed in Appendix F) and other ASD related characteristics (eg. age,sex, ethnicity, etc...) and 1054 participants have been involved. This data has been gathered through the use of the ASD Tests Android Application available on the Google Play Store \cite{app}. 

% {
% \begin{table}[h!]
% \centering
% \begin{tabular}{|c|c|}
% \hline
% Feature &Type (\%) \\
% \hline
% Age in Months & Numerical  \\
% Sex & Numerical \\
% Ethnicity & String  \\
% Jaundice & Yes/No  \\
% Family member with ASD & Yes/No \\
% ASD Traits & Yes/No \\
% \hline
% \end{tabular}
% \caption{Main Data-set Features}
% \label{table:1}
% \end{table}
% }

% \subsection{ML Classification}
% From a first examination of the data-set, has been observed 69\% of the children in the data-set were affected by ASD. The age distribution (in months) of the children is shown in Figure 4.1 (a) and the ratio of boy and girls affected by ASD in this dataset is shown in Figure 4.1 (b).

% \begin{figure}[ht!]%
%     \centering
%     \subfloat[Toddlers age distribution]{{\includegraphics[width=6.9cm]{todage} }}%
%     \qquad
%     \subfloat[Number of boys and girls affected by ASD]{{\includegraphics[width=6.9cm]{todmale} }}%
%     \caption{Data Exploration}%
%     \label{fig:example2}%
% \end{figure}

% As can be seen from Figure 4.1 (a), most of the toddlers affected by ASD are about 36 months old, coincidentally at about three years of age the first sign of autism become more evident. In this data-set the number of boys affected by ASD is about four times higher than the number of girls (Figure 4.1 (b)), this perfectly matches researches statistics. From exploration of this data it has also been possible to notice that more developed countries (eg. United States, United Kingdom, Australia, ect...) are the most affected by ASD and confirmed the expectation that if a family member is affected by ASD it is more likely that other will too. Additionally, it has also been noticed a weak link between ASD and Jaundice. 

% Performing classification using just the Ethnicity, Family member with ASD, Sex, Jaundice Presence and Class/ASD Traits features it has been possible to obtain the following accuracy results:

% {
% \begin{table}[h!]
% \centering
% \begin{tabular}{|c|c|}
% \hline
% Classifier &Accuracy (\%) \\
% \hline
% Logistic Regression & 100  \\
% Random Forest &  95 \\
% Support Vector Machines & 100  \\
% Decision Tree & 89  \\
% Linear Discriminant Analysis & 95 \\
% Gaussian Naive Bayes & 94 \\
% \hline
% \end{tabular}
% \caption{ML Classification Accuracy}
% \label{table:1}
% \end{table}
% }

% This specific features have been selected because retained the ones bringing the most value for classification purposes.

% \subsection{Principal Component Analysis (PCA)}
% Performing PCA, in order to reduce the data-set dimensionality to two dimensions, most of the variance has been preserved (Figure 4.2).

% \begin{figure}[ht!]%
%     \centering
%     \includegraphics[width=6.9cm]{images/todpca.PNG}%
%     \caption{PCA Separation Plot}
% \end{figure}

% Performing the same classification algorithms using the reduced data-set produced the following results:

% {
% \begin{table}[h!]
% \centering
% \begin{tabular}{|c|c|}
% \hline
% Classifier &Accuracy (\%) \\
% \hline
% Logistic Regression & 96  \\
% Random Forest &  96 \\
% Support Vector Machines & 96  \\
% Decision Tree & 96  \\
% Linear Discriminant Analysis & 96 \\
% Gaussian Naive Bayes & 96 \\
% \hline
% \end{tabular}
% \caption{PCA ML Classification Accuracy}
% \label{table:1}
% \end{table}
% }

\section{Faces Responses in Children with ASD}
Children affected by ASD usually show difficulties in comprehending other people's emotions. A study carried out in 2012 by Fabio Apicella, Federico Sicca et al. ("Fusiform Gyrus responses to neutral and emotional faces in children with Autism Spectrum Disorders: a High Density ERP study" \cite{pisa}) aimed to register the EEG response of a group of children (some of which were affected by ASD and some who weren't) to examine their reaction to different forms of stimuli (eg. Happy/Sad/Neutral faces, and images of Cartoons and Trees).

\begin{figure}[ht!]%
    \centering
    \includegraphics[width=6.5cm]{images/stimolus.PNG}%
    \caption{Stimuli used. Image reproduced from: \cite{pisa}}
\end{figure}

Informed consent was given by all the children parent's before undertaking any measurement. Upon Ethics Approval (Appendix F), I made use of the EEG data (in the time-domain) collected during this study to determine whether it was possible to accurately classify which children were affected or not by ASD using Machine Learning. The data-set consisted of the EEG data (for all the five stimuli repeated multiple times) collected from twelve children affected by ASD and twelve who weren't. 

The data originally provided was in a MATLAB format. After a first exploratory analysis, I then decided to convert each file in a CSV format and then merged them so to perform my analysis using Python. I ended up making six CSV files, one for each of the five stimuli and one containing all the five stimuli together.

For each child, the MATLAB data was stored using a three dimensional array. The first dimension represented the number of EEG channels (128), the second dimension represented the number of time-steps (250) and the third dimension the number of repetitions (between 20 and 80, depending on the child). Once the data had been converted in the CSV format, I structured it in a table. This table has 129 columns (one for each channel and one to label the data as either typical or ASD), every 250 rows was stored one stimulus repetition with their correspondent label.

The data-set containing all the five stimulus, had been demonstrated to be balanced, containing 49.03\% of the data of children without ASD and 50.97\% of the data of ASD children. 

All the plots obtained during a first exploration of the data using MATLAB are present in Appendix G. The ML and Deep Leaning results obtained using the individual data-sets for each stimulus are instead present in Appendix H.  

\subsection{ML Classification}
Once I constructed the full data-set containing all the five stimuli, I then decided to try to perform a classification task using Machine Learning. In order to do so, I made use of many Python libraries such as: pandas, numpy, matplotlib.pyplot, sklearn and itertools.

% https://www.overleaf.com/learn/latex/algorithms
\begin{algorithm}[H]
\SetAlgoLined
\KwResult{Write here the result }
 initialization\;
 \While{While condition}{
  instructions\;
  \eIf{condition}{
   instructions1\;
   instructions2\;
   }{
   instructions3\;
  }
 }
 \caption{How to write algorithms}
\end{algorithm}

The pre-processing part consisted of, firstly loading the data, standardising it and then dividing it in training (70\%) and test sets (30\%) for both the inputs (X) and outputs values (Y). The total number of rows in the data-set was equal to 1906500 (934750 rows about typical children EEG data and 971750 about ASD data). Because of the 70\% against 30\% train/test split ratio, 5338 predictions were made during the training set (1334550/250 time-steps) and 2288 predictions during the test set (571950/250 time-steps).

I finally decided to train and then test the binary classification results using different algorithms such as: Logistic Regression, Support Vector Machines (SVM), Decision Trees, Linear Discriminant analysis (LDA) and Gaussian Naive Bayes Classifier (GNB). The classification results are show in Table 4.1. At the output, a zero represent a typical child and a one represents a child affected by ASD. The models used attempted to identify if a child is affected or not by ASD using just a single stimulus repetition ($128 channels \times250 timesteps \times1 repetition$).

{
\begin{table}[h!]
\centering
\begin{tabular}{|c|c|}
\hline
Classifier &Accuracy (\%) \\
\hline
Logistic Regression & 53  \\
Support Vector Machines & 53  \\
Decision Tree & 80  \\
Linear Discriminant Analysis & 53 \\
Gaussian Naive Bayes & 60 \\
\hline
\end{tabular}
\caption{ML Classification Accuracy}
\label{table:1}
\end{table}
}

% \begin{table}[ht!]
%   \centering
%   \label{tbl:excel-table}
%   \includegraphics[width=9cm]{mlt}
%   \caption{ML Classification Accuracy}
% \end{table}

The Decision Tree achieved the most accurate result. Decision Tree is a type of supervised learning algorithm which can be used for either classification or regression tasks. What distinguishes Decision Tree from other ML algorithms, is their ability to display their decision making process using an upside-down tree like representation. In the tree, each node represents a feature in the data-set, each branch a decision rule and each leaf a decision outcome. In this implementation, I decided to use the CART (Classification and Regression Trees) algorithm implementation which makes use of the Gini Index as metric (code available in Appendix E, Listing 3). Appendix I shows the beginning of the decision making process made by the Decision Tree to decide its classification criteria for this data-set.

% \begin{lstlisting}[language=Python, caption=Decision Tree Code]
% trainedtree = tree.DecisionTreeClassifier().fit(X_Train, Y_Train)
% predictionstree = trainedtree.predict(X_Test)
% print(confusion_matrix(Y_Test,predictionstree))
% print(classification_report(Y_Test,predictionstree))
% \end{lstlisting}

% \begin{lstlisting}[firstnumber=1, 
% abovecaptionskip=-5pt,caption= Decision Tree Code,captionpos=b, escapeinside=||]
% |\includegraphics[width=15cm]{3c}%|
% \end{lstlisting}

%\lstlistoflistings

% \lstinputlisting[language=Octave, firstline=2, lastline=12]{BitXorMatrix.m}

% Definition \pythoninline{class MyClass} means \dots

Performing PCA (to reduce data dimensionality to two dimensions) on the data lead to a sharp decrease in accuracy (51\% accuracy at maximum using a Decision Tree).

\begin{figure}[ht!]%
    \centering
    \includegraphics[width=9cm]{images/mlpca.PNG}%
    \caption{PCA Decision Tree Classification Results (0=Typical, 1=ASD)}
\end{figure}

The trained Decision Tree model has then been successfully saved and stored (using the pickle library) to be ready for later use.

\subsection{Deep Learning Classification}
To increase accuracy of results, I then decided to implement Neural Networks (LSTM and CNN). I preferred to use these typologies of ANN instead of a Feed-Forward one because of their ability to work with sequential data. Most of the libraries used for ML Classification have been reused for the Deep Learning implementation, also the train/test ratio split has remained unaltered.

\subsubsection{Long Short-Term Memory}
In order to code this Neutral Network I decided to use the Google Open Source Deep Learning library Tensor-Flow. After careful literature background research, I decided to design the ANN architecture following the "Human Activity Recognition using LSTMs on Android" Medium guide \cite{android}. For this implementation, I decided to change the pre-processing stage and some of the architecture parameters in order to best suit the data-set shape and characteristics (pre-processing code available in Appendix E, Listing 4) . 

% \begin{lstlisting}[language=Python, caption=LSTM Preprocessing]
% segments = []
% for i in range(0, len(df) - N_TIME_STEPS, step):
%     ch = []
%     for j in range(0, N_FEATURES):
%         ch.append(df.iloc[:, j].values[i: i + N_TIME_STEPS])
%     segments.append(ch)
% labels = []
% for i in range(0, len(df) - N_TIME_STEPS, step):
%     label = stats.mode(df['Label'][i: i + N_TIME_STEPS])[0][0]
%     labels.append(label)
% labelsl = np.asarray(pd.get_dummies(labels), dtype = np.float32)
% reshaped_segments = np.asarray(segments, dtype= np.float32).reshape(-1, N_TIME_STEPS, N_FEATURES)
% X_train, X_test, y_train, y_test = train_test_split(
%         reshaped_segments, labelsl, test_size=0.2, random_state=RANDOM_SEED)
% \end{lstlisting}

% \begin{lstlisting}[firstnumber=1, 
% abovecaptionskip=-5pt,caption= LSTM Preprocessing,captionpos=b, escapeinside=||]
% |\includegraphics[width=15cm]{4c}%|
% \end{lstlisting}

{
\begin{table}[h!]
\centering
\begin{tabular}{|c|c|}
\hline
Parameter &Number \\
\hline
Time Steps & 250  \\
Features & 128  \\
Steps & 25  \\
Classes & 2 \\
Hidden Units & 32 \\
L2 Regularization & 0.0015 \\
Learning Rate & 0.0025 \\
Epochs & 50 \\
Batch Size & 256 \\
\hline
\end{tabular}
\caption{LSTM Parameters}
\label{table:1}
\end{table}
}

% \begin{table}[ht!]
%   \centering
%   \label{tbl:excel-table}
%   \includegraphics[width=6cm]{tlstmp}
%   \caption{LSTM Parameters}
% \end{table}

Letting training this model for 50 epochs, using the parameters shown in Table 4.2, lead to an impressive overall validation accuracy of 96.935 \% (The full training accuracy and loss evolution is present in Appendix J). From Figure 4.3, it can be witnessed that both the training/test loss and the training/test accuracy curves closely match. This confirms the correct L2 regularisation (Ridge Regression) parameter was chosen. 

L2 regularisation aims to eliminate over-fitting by minimising the model complexity and loss. By using L2 regularisation, the model complexity is evaluated by summing and squaring all the model feature weights. One of the easier ways to identify overfitting in a model is by comparing the training and test sets loss functions. If the two are really similar, our model is successfully able to generalise to new data without losing accuracy. If instead the two functions are very dissimilar, our model might be able to perform well in the training phase but not during the test phase. Indicating that during the training our model overfitted the data learning also irrelevant information (such as noise) and was not able to correctly classify new data (Bias-Variance Trade-off). 


\begin{figure}[ht!]%
    \centering
    \includegraphics[width=7.5cm]{images/LSTMplot.PNG}%
    \caption{LSTM training/test loss and accuracy against epochs}
\end{figure}

On the other side, the LSTM required a considerable amount of memory and time to train which could potentially become a problem if working with a greater amount of data. To avoid having to retrain the model, it was successfully saved and stored using the pickle library. Different metrics have been performed to test the overall efficiency of the model such as calculating the Confusion Matrix and AUC-ROC curve.

% import os
% file_info = [N_HIDDEN_UNITS, BATCH_SIZE, N_EPOCHS]
% dirname = os.path.dirname("nhid-{}_bat-{}_nepoc-{}/dumps/".format(*file_info))
% if not os.path.exists(dirname):
%     os.makedirs(dirname)
% dirname = os.path.dirname("nhid-{}_bat-{}_nepoc-{}/logs/".format(*file_info))
% if not os.path.exists(dirname):
%     os.makedirs(dirname)
% pickle.dump(predictions, open("nhid-{}_bat-{}_nepoc-{}/dumps/predictions.p".format(*file_info), "wb"))
% pickle.dump(history, open("nhid-{}_bat-{}_nepoc-{}/dumps/history.p".format(*file_info), "wb"))
% tf.train.write_graph(sess.graph, "nhid-{}_bat-{}_nepoc-{}/logs".format(*file_info), 'har.pbtxt')  
% saver.save(sess, 'nhid-{}_bat-{}_nepoc-{}/logs/har.ckpt'.format(*file_info))
% writer = tf.summary.FileWriter('nhid-{}_bat-{}_nepoc-{}/logs'.format(*file_info))
% writer.add_graph(sess.graph)

{
\begin{table}[h!]
\centering
\begin{tabular}{l|l|c|c|c}
\multicolumn{2}{c}{}&\multicolumn{2}{c}{}&\\
\cline{3-4}
\multicolumn{2}{c|}{}&Negative (0)&Positive (1)&\multicolumn{1}{c}{Total}\\
\cline{2-4}
\multirow{}{}{}& Negative (0) & $1093$ & $29$ & $1122$\\
\cline{2-4}
& Positive (1) & $22$ & $1144$ & $1166$\\
\cline{2-4}
\multicolumn{1}{c}{} & \multicolumn{1}{c}{Total} & \multicolumn{1}{c}{$1115$} & \multicolumn{    1}{c}{$1173$} & \multicolumn{1}{c}{$2288$}\\
\end{tabular}
\caption{LSTM Confusion Matrix}
\label{table:1}
\end{table}
}

% \begin{table}[ht!]
%   \centering
%   \label{tbl:excel-table}
%   \includegraphics[width=9.5cm]{2tlstm}
%   \caption{LSTM Confusion Matrix}
% \end{table}

From the Confusion Matrix it is then possible to calculate the model Sensitivity and Specificity.

\begin{align}
\ Sensitivity (TPR) = \dfrac{TP}{TP + FN}\times100\% = \dfrac{1144}{1166}\times100\% = 98.1\% \label{eq:1} \\
\ Specificity (TNR)  = \dfrac{TN}{TN + FP}\times100\%
= \dfrac{1093}{1122}\times100\% = 97.4\%
\end{align}

\begin{figure}[ht!]%
    \centering
    \includegraphics[width=7.5cm]{images/lstmorc.PNG}%
    \caption{LSTM ROC plot}
\end{figure}

All these metrics confirmed that the model did not overfit the data as seen in Figure 4.3. In fact: 
\begin{itemize}
\itemsep0em
\item The ROC curve score was close to 1 (0.997).
\item The number of False Positives and False Negatives in the Confusion Matrix were close to each-other (therefore the model gave the same weight to both classes).
\item Both the Sensitivity and Specificity results were higher than 97\%.
\end{itemize}

\subsubsection{Convolutional Neural Network}
I finally decided to design a CNN in the hope to construct a faster model than the LSTM that would still able to achieve high accuracy. In order to construct the network architecture, I decided to use the Keras Python library. 

The model consisted of: 
\begin{enumerate}
\itemsep0em
\item One 2D Convolutional Layer of 64 filters, a kernel size of $5\times5$, a ReLU (Rectified Linear Unit, Equation 4.3) function and same padding. 
\useshortskip
\begin{align}
\ f(x) = max(0,x)
\label{eq:3}
\end{align}
\useshortskip
\item Another 2D Convolutional Layer having 32 filters, a kernel size of $5\times5$, a ReLU (rectified linear unit) function, same padding and an L2 regularisation coefficient of 0.01 (to prevent overfitting). 
\item A 2D MaxPooling layer of $2\times2$ size.
\item A Dropout layer of 0.2 intensity (in order to avoid over-fitting the data).
\item A layer to first flatten the data from three dimensions to just one, and then another one to condense the input to give to the classifier 128 features (always using the ReLU function and L2 regularisation).
\item A second Dropout layer of 0.5 intensity.
\item Finally, a Dense layer (of two neurons) to produce the classification result, using a Softmax activation function. The Softmax function (Equation 4.4) will take in this case the two inputs from the neurons and convert them in two probabilities that sums up to one. The greater probability was rounded up/down to either one or zero to represent the CNN output choice (Typical(0), ASD(1)).
% \setlength{\floatsep}{-2pt}
\begin{align}
\ \sigma(x)_{j} = \frac{e^{x_{j}}}{\sum_{k=1}^{k} e^{x_{k}}} && \text{for j=1,\dots,k}
\label{eq:3}
\end{align}
% \useshortskip
\end{enumerate}

In order to optimise the training, the Adam (Adaptive Moment Estimation) gradient descent algorithm was used, and the cross-entropy function was used to compute the model loss. The cross-entropy function ($H_{y'}(y)$), in a binary classification case can be calculated by using Equation 4.5.
\useshortskip
\begin{align}
\ H_{y'}(y) = \sum_{i} (y_{i}'\log(y_{i}) + (1 - y_{i}')\log(1 - y_{i}))
\label{eq:3}
\end{align}
\useshortskip
\begin{conditions}
 y_{i}'  &  expected model output \\
 y_{i}     &  real model output \\
\end{conditions}
\useshortskip
This model achieved an overall validation accuracy of 94.58\% in just thirty epochs of training. 

\begin{figure}[ht!]%
    \centering
    \subfloat[CNN Accuracy against epoch number]{{\includegraphics[width=6.9cm]{cnn1} }}%
    \qquad
    \subfloat[CNN Loss against epoch number]{{\includegraphics[width=6.9cm]{cnn2} }}%
    \caption{CNN Model Training}%
    \label{fig:example2}%
\end{figure}

Both the LSTM and the CNN are able to classify if a child is affected or not by ASD just by observing one stimulus repetition (128 channels, 250 time-steps, 1 repetition, 1 stimulus). The overall accuracy of the CNN was 2\% lower compared to the LSTM one, but the training time and amount of power needed to run this model was much lower. Also this model was successfully saved and stored (in a json and h5 file type) for later use (Code available in Appendix E, Listing 5). 

% \begin{lstlisting}[language=Python, caption=Storing CNN Model]
% model_json = model.to_json()
% with open("model.json", "w") as json_file:
% json_file.write(model_json)
% model.save_weights("model.h5")
% \end{lstlisting}

% \begin{lstlisting}[firstnumber=1, 
% abovecaptionskip=-5pt,caption= Storing CNN Model,captionpos=b, escapeinside=||]
% |\includegraphics[width=15cm]{5c}%|
% \end{lstlisting}

Also in this case different metrics have been performed to test the overall efficiency of the model such as calculating the Confusion Matrix and AUC-ROC Curve.

% \clearpage

{
\begin{table}[h!]
\centering
\begin{tabular}{l|l|c|c|c}
\multicolumn{2}{c}{}&\multicolumn{2}{c}{}&\\
\cline{3-4}
\multicolumn{2}{c|}{}&Negative (0)&Positive (1)&\multicolumn{1}{c}{Total}\\
\cline{2-4}
\multirow{}{}{}& Negative (0) & $1001$ & $100$ & $1101$\\
\cline{2-4}
& Positive (1) & $24$ & $1163$ & $1187$\\
\cline{2-4}
\multicolumn{1}{c}{} & \multicolumn{1}{c}{Total} & \multicolumn{1}{c}{$1025$} & \multicolumn{    1}{c}{$1263$} & \multicolumn{1}{c}{$2288$}\\
\end{tabular}
\caption{CNN Confusion Matrix}
\label{table:1}
\end{table}
}

% \begin{table}[ht!]
%   \centering
%   \label{tbl:excel-table}
%   \includegraphics[width=9.5cm]{3tcnn}
%   \caption{CNN Confusion Matrix}
% \end{table}

From the Confusion Matrix it is then possible to calculate the model Sensitivity and Specificity.

\begin{align}
\ Sensitivity (TPR) = \dfrac{TP}{TP + FN}\times100\% = \dfrac{1163}{1187}\times100\% = 97.9\% \label{eq:1} 
\\
\ Specificity (TNR)  = \dfrac{TN}{TN + FP}\times100\%
= \dfrac{1001}{1101}\times100\% = 90.9\% 
\end{align}

\begin{figure}[ht!]%
    \centering
    \includegraphics[width=7.5cm]{images/cnnorc.PNG}%
    \caption{CNN ROC Curve}
\end{figure}

For the same reasons examined in the LSTM analysis, the CNN model does not seem to be affected by over-fitting. However, the CNN performed overall worse than the LSTM. That's because of the bigger difference between the registered False Positives and False Negatives in the Confusion Matrix, which caused the Specificity score to be negatively affected.

\section{Autism Study Using Behaviour Imaging}
Computer Vision is an AI area which has seen exponential improvements during the last few years, especially because of the introduction of Convolutional Neural Networks. According to some research papers such as "Computer vision and behavioral phenotyping: an autism case study" \cite{visionpaper1} and "Behavior Imaging: Using Computer Vision to Study Autism" \cite{visionpaper2}, this subject can potentially have an huge impact in ASD detection in children. This can be done by: 
\begin{enumerate}
\itemsep0em
\item Making Computer Vision games to test child's ability to recognise and imitate facial expressions or feelings.
\item Recording the child-therapist sessions to then examine the recording to find out if the child has shown: some reaction delay to the applied stimulus, any repetitive behaviour or any abnormal walking/speaking behaviour.
\end{enumerate}

\subsection{Game Application}
As part of this project I decided to design a game to test a child's ability to make a series of facial expressions. In order to realise this game, I partially followed the "Real Time Facial Expression Recognition on Streaming Data" post by Sefik Ilkin Serengil \cite{visiongame} to make use of his pre-trained model for facial expression recognition. I successively coded the game using Python libraries such as: cv2, keras, tkinter and PIL.

\begin{figure}[ht!]%
    \centering
    \subfloat[Game Window]{{\includegraphics[width=6.9cm]{visgame2} }}%
    \qquad
    \subfloat[Camera Window]{{\includegraphics[width=6.3cm]{visgame1} }}%
    \caption{Computer Vision Game}%
    \label{fig:example2}%
\end{figure}

The game interface is formed by two windows. In the first one, the user is told if their face is correctly detected and what facial expression they should perform (Figure 4.7 (a)). In the second one, the camera recording is displayed and if a face is detected an empty rectangle will cover the face area displaying on the top left corner the detected expression (Figure 4.7 (b)). Once the user has made the asked expression, a pop-up window will appear to congratulate the user and the first window will update to ask to make a different face expression. The list of available face expressions consist of: angry, fear, happy, sad, surprise and neutral faces.
