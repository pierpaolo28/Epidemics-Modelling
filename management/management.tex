\chapter{Project Management}

\label{ch:management}
\setlength\lineskip{0pt}
\vspace*{15pt}

\section{Time Management}
Throughout this project I made use of backup repositories such as:

\begin{itemize}
\itemsep0em
\item Dropbox = to store files related to this project, and to be able to access them from any type of station at any moment.
\item Google Drive = to store and share (to selected users) project hardware and software advancements (images and videos).
\item University of Southampton GitLab = to retain a version-control of all the written code.
\end{itemize}

Appendix A provides a wealth of project management tools which have been used throughout this project:

\begin{enumerate}
\itemsep0em
\item A table representation of the executed tasks during the project, including the planned start date, months of execution and weeks to complete each task. 
\item A Gantt Chart of the planned time-schedule.
\item A Gantt Chart of the actual time-schedule.
\item A Risk Assessment Matrix to display all the possible risks associated with this project.
\item A Work Breakdown Structure to show in a tree-like representation the identified main tasks of this project. 
\end{enumerate}

A Hardware Costs report of the project can be found in Appendix D.

Appendix L provides the total report word count, while Appendix K the Design Archive Guide.

\section{Ethics Application}
Appendix F provides the Ethics Application necessary to carry out the data-sets exploration. This approval has been obtained by the University of Southampton Ethics Committee through application using the ERGO \RNum{2} portal.

\section{Project Challenges}
Throughout this project, many challenges have been faced and overcome. Some of these can be noticed from the differences between the Planned and Actual Gantt Charts provided in Appendix A. 

One of the main challenges I faced, was the first exploratory data analysis of the used data-set. The original data-set was not in fact structured in a suitable way to be used for Deep Learning applications. After a first unsuccessful attempt to use the MATLAB Deep Learning Toolbox with the original data-set, I therefore decided to restructure the whole data-set and to convert it in a CSV format. This process, although being time consuming, resulted to be a successful approach. Having the inputs features in the right shapes allowed me to make the design of the LSTM and CNN architectures much easier. Additionally, this new restructured data-set can now be used not just in MATLAB but also with other programming languages such as Python and R (making this data-set more accessible to anyone in case of future further developments).